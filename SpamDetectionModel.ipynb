{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Eg: Spam.txt file**\n",
        "\n",
        "**Subject:** Congratulations! You've Won $100,000 Cash Prize\n",
        "\n",
        "Dear George,\n",
        "\n",
        "I am thrilled to inform you that you are the lucky winner of our recent contest and have been awarded a cash prize of $100,000! Your participation and enthusiasm are truly appreciated, and we couldn't be happier to share this exciting news with you.\n",
        "\n",
        "Regards,  \n",
        "idontSmile\n",
        "\n",
        "\n",
        "## **Eg: NSpam.txt**\n",
        "\n",
        "**Subject:** Invitation for Dinner\n",
        "\n",
        "Dear Friend,\n",
        "\n",
        "I hope this email finds you well. I wanted to extend a warm invitation to you for a dinner party at my home on **18/8/2023**, next Friday. It would be wonderful to have you join us.\n",
        "\n",
        "Best regards,  \n",
        "iSmile\n"
      ],
      "metadata": {
        "id": "CJeQf1Ym-r5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D6-1iiLJr0G",
        "outputId": "06afb564-abf6-467a-c186-edc23f12059b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5000 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5000 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5000 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5000 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5000 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5000 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5000 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ac7f2d1c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
            "Sample email (Spam.txt): SPAM\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Example data (expand with more data for better performance)\n",
        "emails = [\n",
        "    \"Buy cheap watches! Free shipping!\",\n",
        "    \"Meeting for lunch today?\",\n",
        "    \"Claim your prize! You've won $1,000,000!\",\n",
        "    \"Important meeting at 3 pm.\",\n",
        "    \"You're invited to a dinner party at my place.\",\n",
        "    \"Exclusive deal just for you!\",\n",
        "    \"How about a catch-up call this weekend?\",\n",
        "    \"Congratulations! You've won a prize!\"\n",
        "]\n",
        "labels = [1, 0, 1, 0, 0, 1, 0, 1]\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "# Preprocess the email data\n",
        "emails = [preprocess_text(email) for email in emails]\n",
        "\n",
        "# Tokenize and pad the email text data\n",
        "max_words = 1000\n",
        "max_len = 50\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(emails)\n",
        "sequences = tokenizer.texts_to_sequences(emails)\n",
        "X_padded = pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to NumPy arrays to ensure compatibility\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Define the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_words, output_dim=32, input_length=max_len),\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "model.fit(np.array(X_train), y_train, epochs=10, validation_data=(np.array(X_test), y_test), verbose=1)\n",
        "\n",
        "# Test the model\n",
        "sample_file_path = \"Spam.txt\"\n",
        "try:\n",
        "    with open(sample_file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        sample_email_text = file.read()\n",
        "\n",
        "    # Preprocess the sample email text\n",
        "    sample_email_text = preprocess_text(sample_email_text)\n",
        "    sample_sequences = tokenizer.texts_to_sequences([sample_email_text])\n",
        "    sample_email_padded = pad_sequences(sample_sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "    # Prediction\n",
        "    prediction = model.predict(sample_email_padded)\n",
        "    threshold = 0.5\n",
        "\n",
        "    if prediction[0][0] > threshold:\n",
        "        print(f\"Sample email ({sample_file_path}): SPAM\")\n",
        "    else:\n",
        "        print(f\"Sample email ({sample_file_path}): NOT SPAM\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {sample_file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    }
  ]
}